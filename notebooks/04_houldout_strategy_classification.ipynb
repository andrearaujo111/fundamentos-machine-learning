{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe97ff9",
   "metadata": {},
   "source": [
    "# 1.0 IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad530b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:43.870240Z",
     "start_time": "2023-03-03T22:05:42.666504Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.tree as tree\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57d150",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0 CREATE SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd40968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:43.893778Z",
     "start_time": "2023-03-03T22:05:43.874283Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define data generator parameters\n",
    "n_samples = 5000\n",
    "n_features = 5\n",
    "n_informative = 2\n",
    "n_redundant = 3\n",
    "n_classes = 2\n",
    "random_state = 44\n",
    "\n",
    "# Create data\n",
    "X, y = datasets.make_classification(n_samples=n_samples, n_features=n_features, n_informative=n_informative, \n",
    "                                    n_redundant=n_redundant, random_state=random_state, n_classes=n_classes)\n",
    "\n",
    "# Showing how's the dataset looks like\n",
    "df1 = pd.concat([pd.DataFrame(X), pd.DataFrame(y, columns=['response'])], axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b72ec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will separate data here simulating available data (which will perform train, test and validation) and production data, which will simulate data on production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb60fae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:43.926347Z",
     "start_time": "2023-03-03T22:05:43.897809Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split datasets\n",
    "X, X_prod, y, y_prod = ms.train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44701f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T17:10:48.743506Z",
     "start_time": "2023-02-28T17:10:48.735874Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# 3.0 FIRST SCENARIO (NO SPLITTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe20de7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-28T17:25:59.695576Z",
     "start_time": "2023-02-28T17:25:59.689358Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.1 Prediction over training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e81ee1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:43.963845Z",
     "start_time": "2023-03-03T22:05:43.930642Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create decision tree classifier object\n",
    "model = tree.DecisionTreeClassifier(max_depth=9)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Check metrics\n",
    "acc = metrics.accuracy_score(y, y_hat)\n",
    "prec = metrics.precision_score(y, y_hat, average='weighted')\n",
    "rec = metrics.recall_score(y, y_hat, average='weighted')\n",
    "\n",
    "print('Accuracy over training: {}'.format(acc))\n",
    "print('Precision over training: {}'.format(prec))\n",
    "print('Recall over training: {}'.format(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83363358",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.2 Prediction over production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e3e30f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:43.979316Z",
     "start_time": "2023-03-03T22:05:43.966711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_hat_prod = model.predict(X_prod)\n",
    "\n",
    "# Check metrics\n",
    "acc_prod = metrics.accuracy_score(y_prod, y_hat_prod)\n",
    "prec_prod = metrics.precision_score(y_prod, y_hat_prod, average='weighted')\n",
    "rec_prod = metrics.recall_score(y_prod, y_hat_prod, average='weighted')\n",
    "\n",
    "print('Accuracy over training: {}'.format(acc_prod))\n",
    "print('Precision over training: {}'.format(prec_prod))\n",
    "print('Recall over training: {}'.format(rec_prod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573242f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What happened here is that we used all available data only for training, and when we put it into production and ran the algorithm and captured performance on production data, we saw that performance was about 8% lower. This indicates that the algorithm is overfitted, although not so much as it has good generalization capacity, 80% is not all bad. However, the difference can negatively impact the business, causing loss of revenue or reputation.\n",
    "\n",
    "To mitigate this issue and evaluate the real generalization capacity of the algorithm before going into production, we will call upon our friend, the trai-testing strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122bab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T23:07:32.649584Z",
     "start_time": "2023-03-02T23:07:32.643204Z"
    }
   },
   "source": [
    "# 4.0 SECOND SCENARIO - TRAIN/TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a669ea40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:43.987756Z",
     "start_time": "2023-03-03T22:05:43.982483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677ef01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T23:07:52.529517Z",
     "start_time": "2023-03-02T23:07:52.517848Z"
    }
   },
   "source": [
    "### 4.1 Train with train data and predictions and performance with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc95100c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:44.018939Z",
     "start_time": "2023-03-03T22:05:43.991337Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create decision tree classifier object\n",
    "model = tree.DecisionTreeClassifier(max_depth=15)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "# Check metrics\n",
    "acc_test = metrics.accuracy_score(y_test, y_hat_test)\n",
    "prec_test = metrics.precision_score(y_test, y_hat_test, average='weighted')\n",
    "rec_test = metrics.recall_score(y_test, y_hat_test, average='weighted')\n",
    "\n",
    "print('Accuracy over training: {}'.format(acc_test))\n",
    "print('Precision over training: {}'.format(acc_test))\n",
    "print('Recall over training: {}'.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e9a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T23:23:46.659958Z",
     "start_time": "2023-03-02T23:23:46.657178Z"
    }
   },
   "source": [
    "### 4.2 Find the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1025d846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:44.506954Z",
     "start_time": "2023-03-03T22:05:44.022201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list that will serve as parameter\n",
    "values = [i for i in range(1, 40)]\n",
    "\n",
    "# Create an empty list to save the results\n",
    "test_scores = []\n",
    "\n",
    "for i in values:\n",
    "    \n",
    "    # Create decision tree classifier object\n",
    "    model = tree.DecisionTreeClassifier(max_depth=i)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    acc_test = metrics.accuracy_score(y_test, y_hat_test)\n",
    "    \n",
    "    test_scores.append(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13fabfab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:44.691131Z",
     "start_time": "2023-03-03T22:05:44.509941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_scores,'-o', label='test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae62dee",
   "metadata": {},
   "source": [
    "The best parameter is **3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a5fcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T20:37:11.492136Z",
     "start_time": "2023-03-03T20:37:11.487052Z"
    }
   },
   "source": [
    "### 4.3 Publish model into production with the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18dcf7bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:44.714159Z",
     "start_time": "2023-03-03T22:05:44.695641Z"
    }
   },
   "outputs": [],
   "source": [
    "model_prod = tree.DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Concatenate train and test data\n",
    "X = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "# Train the model\n",
    "model_prod.fit(X, y)\n",
    "\n",
    "# Prediction over production \n",
    "y_hat_prod = model_prod.predict(X_prod)\n",
    "\n",
    "acc_prod = metrics.accuracy_score(y_prod, y_hat_prod)\n",
    "prec_prod = metrics.precision_score(y_prod, y_hat_prod, average='weighted')\n",
    "rec_prod = metrics.recall_score(y_prod, y_hat_prod, average='weighted')\n",
    "\n",
    "print('Accuracy over production {}'.format(acc_prod))\n",
    "print('Precision over production: {}'.format(acc_prod))\n",
    "print('Recall over production: {}'.format(acc_prod)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922c206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T20:39:36.132177Z",
     "start_time": "2023-03-03T20:39:36.123842Z"
    }
   },
   "source": [
    "In this case, we trained the model on the training data and made predictions on the test data. We could see that the prediction results were lower than the initial results, and matched the performance of the predictions made on the production data that we saw in the first scenario.\n",
    "\n",
    "However, we also saw the possibility of improving the model by seeking to locate the best value for the **max_depth** parameter. To do this, we iterated over a given range, training the algorithm at each iteration with the training data, making predictions, and measuring performance with test data. Each iteration generated a performance result, which we saved in a list and then plotted.\n",
    "\n",
    "Having found the best value, we retrained using the best parameter, and when measuring the result, let's suppose we obtained a worse result on the production data. Why would this have happened?\n",
    "\n",
    "The reason would be that the test set was used multiple times by the model, when these data, to measure performance, need to represent data never before seen by the model. However, when we iterate over them using the trained model, the data is seen by the model and the model is optimized according to the applied parameters. In other words, the algorithm's ability to memorize is increased due to the use of the test set to make multiple predictions on a model that was replicated several times. This means that the algorithm's memorization capacity is greater, but it does not perform as well as on new data.\n",
    "\n",
    "One way to mitigate this is the **train-validation-test** strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13dfe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:08:02.695053Z",
     "start_time": "2023-03-03T21:08:02.687940Z"
    }
   },
   "source": [
    "## 5.0 TRAIN/VALIDATION/TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413591fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:08:20.907810Z",
     "start_time": "2023-03-03T21:08:20.899851Z"
    }
   },
   "source": [
    "**Just remembering, we already have a test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370f2075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:44.781399Z",
     "start_time": "2023-03-03T22:05:44.716846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_val, y_train, y_val = ms.train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95903e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:45.313102Z",
     "start_time": "2023-03-03T22:05:44.786712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the best parameter\n",
    "# Create a list that will serve as parameter\n",
    "values = [i for i in range(1, 40)]\n",
    "\n",
    "# Create an empty list to save the results\n",
    "test_scores = []\n",
    "\n",
    "for i in values:\n",
    "    \n",
    "    # Create decision tree classifier object\n",
    "    model = tree.DecisionTreeClassifier(max_depth=i)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_hat_val = model.predict(X_val)\n",
    "    acc_val = metrics.accuracy_score(y_val, y_hat_val)    \n",
    "    test_scores.append(acc_val)\n",
    "    \n",
    "plt.plot(test_scores, '-o', label='validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c0632",
   "metadata": {},
   "source": [
    "The best parameter is **2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c456af77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:45.326095Z",
     "start_time": "2023-03-03T22:05:45.316727Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction over validation\n",
    "y_hat_val = model.predict(X_val)\n",
    "acc_val = metrics.accuracy_score(y_val, y_hat_val)\n",
    "print('Accuracy over validation {}'.format(acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9fee514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:45.345780Z",
     "start_time": "2023-03-03T22:05:45.329988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model trained with the best parameter (train+val)\n",
    "model_train = tree.DecisionTreeClassifier(max_depth=2)\n",
    "model_train.fit(np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val)))\n",
    "\n",
    "# Performance over test\n",
    "y_hat_test = model_train.predict(X_test)\n",
    "acc_test = metrics.accuracy_score(y_test, y_hat_test)\n",
    "print('Accuracy over test {}'.format(acc_val))\n",
    "\n",
    "# Performance over production\n",
    "y_hat_prod = model_train.predict(X_prod)\n",
    "acc_prod = metrics.accuracy_score(y_prod, y_hat_prod)\n",
    "print('Accuracy over production {}'.format(acc_prod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d7079",
   "metadata": {},
   "source": [
    "In this scenario, we separated a portion of the training data for validation, using only these data to iterate and find the best parameter for the algorithm. Once this was done, we combined the training and validation data, forming a new dataset of training, and trained the model with the best parameter. Then, we applied the model to the test data and validated the performance on the test data.\n",
    "\n",
    "We achieved a total of 88.2%. Then, we checked the performance on the production data and got a result of 89.9%. Therefore, we can say that the model's performance in production is very close to the performance in the test environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac7bb9",
   "metadata": {},
   "source": [
    "# 5.0 TRAIN/VALIDATION/TEST STRATEGY FOR KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f362d5ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:45.378686Z",
     "start_time": "2023-03-03T22:05:45.349129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../datasets/train.csv')\n",
    "\n",
    "# Features\n",
    "features = df.select_dtypes(exclude='object').columns.to_list()\n",
    "target = 'limite_adicional'\n",
    "\n",
    "# Define datasets\n",
    "X = df.loc[:, features]\n",
    "y = df.loc[:, target].values.ravel()\n",
    "\n",
    "# Split train-test\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# Split train-validation\n",
    "X_train, X_test, y_val, y_val = ms.train_test_split(X_train, y_train, test_size = 0.05, random_state=42)\n",
    "\n",
    "# Test the best parameter\n",
    "\n",
    "values = [i for i in range(1, 40, 2)]   \n",
    "scores = []\n",
    "\n",
    "for i in values:\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    \n",
    "    #model.fit(X_train, y_train)\n",
    "    \n",
    "    #yhat_val = model.predict(X_val)\n",
    "    #acc_val = metrics.accuracy_score(y_val, yhat_val)\n",
    "    \n",
    "    # scores.append(acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a6e2d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:45.388882Z",
     "start_time": "2023-03-03T22:05:45.382623Z"
    }
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d876967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T22:05:45.399213Z",
     "start_time": "2023-03-03T22:05:45.391689Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a1c351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
